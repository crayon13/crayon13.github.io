---
layout: post
title: "엘라스틱서치 실무 가이드"
category: books
tags: 
    - "elastic search"
    - 개발
comments: true
---
# 1. 검색 시스템 이해하기
## 1.1 검색 시스템의 이해
### 1.1.1 검색 시스템이란?
`검색 서비스 > 섬색 시스탬 > 검색 엔진`

엘라스틱서치는 검색엔진이다.
### 1.1.2. 검색 시스템의 구성요소
- 스토리지
- 색인기
- 검색기

### 1.1.3. 관계형 데이터베이스와의 차이점
**구조와용어의 비교**

엘라스틱서치 | 관계형 데이터베이스
-----| ----
인덱스 (Index) | 데이터베이스 (Database)
샤드 (Shard) | 파티션 (Partition)
타입 (Type) | 테이블 (Table)
문서 (Document) | 행 (Row) -> Record가 더 적당할 듯
필드 (Field) | 열 (Column)
매핑 (Mapping) | 스키마 (Schema)
Query DSL | SQL

**추가, 검색, 삭제, 수정 기능 비교**
- 엘라스틱서치는 RESTful API를 사용

HTTP 메서드 | 기능 | 데이터베이스 질의 문법
----|----|---- 
GET | 데이터 조회 | SELECT
PUT | 데이터 생성 | INSERT
POST | 데이터 업데이트, 조회 | UPDATE, SELECT
DELETE | 데이터 삭제 | DELETE
HEAD | 인덱스의 정보 확인 | - 


엘라스틱서치 API 구조
```
curl -X (메서드) http://host:port/(인덱스)/(타입)/(문서 id) -d '{json 데이터}'
```
DBMS와 비교해 보자
```
SELECT * FROM user WHERE name like '%가마돈%'

GET http://localhost:9200/user/_search?q=Name:가마돈
```
결과는 다음과 같이
```json
{
    "Id":1,
    "Name" : "가 마 돈", "Location": "서울", 
    "Gender" : "남",
    "Date":"2018-05-12"
}
```

## 1.2 검색 시스템과 엘라스틱서치
### 1.2.1 엘라스틱서치가 강력한 이유
- 오픈소스 검색엔진
- 전문 검색 (Full Text Search)
- 통계 분석
- 스키마리스 (Schemaless)
    - 데이터베이스는 스키마라는 구조에 따라 데이터를 적합한 형태로 변경해서 저장하고 관리한다.
    - 반면 엘라스틱서치는 정형화되지 않은 다양한 형태의 문서도 자동으로 색인하고 검색할 수 있다.
- RESTful API
- 멀티테넌시 (Multi-tenancy)
    - 서로 상이한 인덱스일지라도 검색할 필드명만 같으면 여러개의 인덱스를 한번에 조회 할 수 있다. 이를 이용해 멀티테넌시 기능을 제공할 수 있다.
- Document-Oriented
    - 여러 계증의 데이터를 JSON 형식의 구조화된 문서로 인덱스에 저장할 수 있다.
    계층 구조로 문서도 한번의 쿼리로 쉽게 조회 할 수 있다.
- 역색인 (Inverted Index)
    - 엘라스틱서치는 루씬기반으로 역색인을 지원한다.
    - 역색인이란 종이책의 마지막 페이지에서 제공하는 색인 페이지와 비슷하게 제공되는 특수한 데이터 구조다.
- 확장성과 가용성

### 1.2.2 엘라스틱서치의 약점
- 실시간이 아니다.
    - 일반적으로 색인된 데이터는 통상적으로 1초 뒤에나 검색이 가능해 진다.
- 트랜잭션과 롤백 기능을 제공하지 않는다.
- 데이터의 업데이트를 제공하지 않는다.
    - 삭제, 생성의 과정을 거친다.

## 1.3 실습 환경 구축
- 주요 설정

설정 | 설명
--- | ---
cluster.name | 클러스터..
node.name | 1개의 클러스터는 N개의 노드를 가질 수 있다.
path.data | 엘라스틱서치의 인덱스 경로를 지정한다.<br/>설정하지 않으면 기본적으로 엘라스틱서치 하위의 data 디렉토리에 인덱스가 생성된다.
path.logs | 노드와 클러스터에서 생성되는 로그 경로 지정
path.repo | 인덱스를 백업하기 위한 스냅샷 경로를 지정
network.host | 특정 IP만 접근허용 0.0.0.0 은 전체 허용
http.port | 클라인트가 접근할 수 있는 http 포트 번호 - 기본 9200
transport.tcp.port | 클라인트가 접근할 수 있는 TCP 포트 - 기본 9300
discovery.zen.ping.unicast.hosts | 노드가 N개인 경우 유니캐스트로 활성화된 다른 서버를 찾는다.<br/>클러스터로 묶인 노드(서버)의 IP를 지정하면 된다.<br/>노드가 2개인 경우 `[1.1.1.1, 2.2.2.2]` 형태로 선언
discovery.zen.minimum_master_nodes | 마스터 노드의 선출 기준이 되는 노드의 수를 지정한다.
node.master | 마스터 노드로 동작 여부를 지정한다.
node.data | 데이터 노드로 동작 여부를 지정한다.

# 2. 엘라스틱서치 살펴보기
## 2.1 엘라스틱서치를 구성하는 개념
### 2.1.1 기본 용어
- 전체 구조
    - Index > Type > Document > Field, Field...

- 인덱스 (Index)
    - 인덱스는 데이터 저장 공간이다.
    - 하나의 인덱스는 하나의 타입만 가지며 하나의 물리적인 노드에 여러 개의 논리적 인덱스를 생성 할 수 있다.
    - 검색 시 인덱스 이름으로 문서 데이터를 검색하며, 여러 개의 인덱스를 동시에 검색하는 것도 가능하다.
    - ES를 분산 환경으로 구성하면 하나의 인덱스가 여러 노드에 분산 저장된다.
    - 인덱스 생성 시 기본적으로 5개의 Primary 샤드 1개의 Replica 샤드 세트를 생성한다.
    - 각각의 샤드 수는 인덱스를 생성할 때 옵션으로 변경 할 수 있다.
    - 인덱스 이름은 모두 소문자여야 하며 추가, 수정, 삭제, 검색은 RESTful API로 수행할 수 있다.
    - 만약 인덱스가 없는 상태에서 데이터가 추가도니다면 데이터를 이용해 인덱스가 자동 생성된다.
- 샤드 (Shard)
    - 색인된 문서는 하나의 인덱스에 담긴다.
    - 인덱스 내부에 색인된 데이터는 물리적 공간에 여러 개의 파티션으로 나뉘어 구성되는데, 이 파티션을 엘라스틱서치에서는 샤드라고 부른다.
    - es는 다수의 샤드로 문서를 분산 저장하고 있어 데이터 손실 위험을 최소화 할 수 있다.
- 타입 (Type)
    - 타입은 인덱스의 논리적 구조를 의미하며, 인덱스 속성에 따라 분류하기도 한다.
    - es 6.0 이하 버전에서는 하나의 인덱스에 여러 타입을 설정 가능했지만.
    - 6.1 부터 인덱스당 하나의 타입만 사용할 수 있다.
- 문서 (Document
    - es에서 데이터가 저장되는 최소 단위다
    - JSON 포맷으로 데이터가 저장된다.
- 필드 (Field)
    - 필드는 문서를 구성하기 위한 속성이라고 할수 있다.
    - 일반적으로 데이터베이서의 컬럼과 비교 할 수 있으나 컬럼이 정적(Static) 인 데이터 타입이라면
    - 필드는 좀 더 동적 (Dynamic)인 데이터 타입이라고 할 수 있다.
    - 하나의 필드는 목적에 따라 다수의 데이터 타입을 가질 수 있다.
        - 영화 제목 필드는 검색할 때 매칭 검색 혹은 초성 검색이 모두 지원되도록 2개의 데이터 타입을 가져야 한다.
- 매핑 (Mapping)
    - 매핑은 문서의 필드와 필드의 속성을 정의하고 그에 따른 색인 방법을 정의하는 프로세스다.
    - 인덱스의 매핑 정보에는 여러 가지 데이터 타입을 지정할 수 있지만 필드명은 중복해서 사용할 수 없다.
    
### 2.1.2 노드의 종류
클러스터는 물리적인 노드 인스턴스들의 모임이다.
클러스터는 모든 노드의 검색과 색인 작업을 관장하는 논리적인 개념.
- 마스터 노드 (Master Node)
    - 노드의 추가와 제거, 인덱스의 생성과 삭제 등 클러스터와 관련된 전반적인 작업을 담당한다.
    - 네트워크 속도가 빠르고 지연이 없는 노드를 마스터 노드로 선정해야 한다.
    - 다수의 노드를 마스터로 설정할 수 있지만 결과적으로 하나의 노드만이 마스터 노드로 선출되어 동작한다.
- 데이터 노드 (Data Node)
    - 실질적인 데이터를 저장한다.
    - 검색과 통계 같은 데이터 관련 작업을 수행한다.
    - 데이터가 실제로 분산 저장되는 물리적 공간인 샤드가 배치되는 노드이기도 하다.
    - 색인 작업은 CPU, 메모리, 스토리지 같은 컴퓨팅 리소스를 많이 소모하기 때문에 리소스 모니터링이 필요하다.
    - 데이터 노드는 가능한 한 마스터 노드와 분리해서 구성하는게 좋다.
- 코디네이팅 노드 (Coordinating Node)
    - 사용자의 요청만 받아서 처리한다.
    - 클러스터 관련 요청은 마스터 노드에 전달하고 데이터 관련 요청은 데이터 노드에 전달한다.
- 인제스트 노드 (Ingest Node)
    - 문서의 전처리 작업을 담당한다.
    - 인덱스 생성 전 문서의 형식을 다양하게 변경 할 수 있다.

**샤드**
    - 프라이머리 샤드와 레플리카 샤드로 구분
    - 장애 발생 시 마스터 노드는 데이터를 재분배하거나 레플리카 샤드를 프라이머리 샤드로 승격시켜 서비스 중단 없는 복구가 가능해진다.

## 2.2 엘라스틱서치에서 제공하는 주요 API
**API의 종류**
- 인덱스 관리 API (Indices API)
- 문서 관리 API (Document API) : 문서의 추가/수정/삭제
- 검색 API (Search API) : 문서 조회
- 집계 API (Aggregation API) : 문서 통계

`스키마리스 기능은 가급적이면 사용하지 말자.`
- 스키마리스는 인덱스를 자동으로 생성하는데 필드 정보가 매핑되지 않아 의도와 다르게 동작할 수 있다.
- 또한 필드에 중복 타입이 지정되어 Standard Analyzer를 사용하게 된다.

`스키마리스 기능을 명시적으로 사용하지 않도록 설정하는 방법`
- 노드 설정 파일에서 action.auto_create_index = false로 정의
- 인덱스 별로 제공되는 index.mapper.dynamic = false 로 설정하여 컬럼의 자동 매핑 생성을 비활성화

### 2.2.1 인덱스 관리 API
**인덱스 생성**
- 인덱스를 생성 할 때는 매핑이라는 세부 설정을 이용할 수 있다.
- 매핑은 문서와 문서에 포함된 필드, 필드 타입을 세세하게 지정 가능하다.

```json
PUT /movie
{ 
    "settings" : {
        "number_of_shards" :3,
         "number_of_replicas" :2
    }
},
"mappings" : { 
    "_doc" : {
        "properties" : {
            "movieCd" :{ "type" :"integer" }, 
            "movieNm": { "type" :"text" }, 
            "movieNmEn" : { "type" : "text" },
            "prdtYear" :{ "type1" :"integer" },
            "openDt" : { "type" : "date" }, 
            "typeNm" : { "type" : "keyword" }, 
            "prdtStatNm" : { "type" : "keyword" }, 
            "nationAlt":{ "type" : "keyword" }, 
            "genreAlt" :{ "type" :"keyword" }, 
            "repNationNra" : { "type" : "keyword" }, 
            "repGenreNm" : { "type" : "keyword" }
        } 
    }
}
```
- 결과는
```json
{
    "acknowledged": true,
    "shards_acknowledged": true,
    "index": "movie"
}
```

**인덱스 삭제**
```
DELETE /movie
```
- 결과는
```json
{
    "acknowledged": true
}
```
- 인덱스 이름이 잘못되었거나 없을 경우는
```json
{
    "error": {
        "root_cause": [
            {
                "type": "index_not_found_exception",
                "reason": "no such index",
                "resource.type": "index_or_alias",
                "resource.id": "movie",
                "index_uuid": "_na_",
                "index": "movie"
            }
        ],
        "type": "index_not_found_exception",
        "reason": "no such index",
        "resource.type": "index_or_alias",
        "resource.id": "movie",
        "index_uuid": "_na_",
        "index": "movie"
    },
    "status": 404
}
```
`인덱스는 한번 삭제하면 복구 할 수 없다!!`

### 2.2.2 문서관리 API
문서관리 API는 실제 문서를 색인하고 조회, 수정, 삭제를 지원하는 API다.
- `Index API` : 한 건의 문서를 색인한다.
- `Get API` : 한 건의 문서를 조회한다.
- `Delete API` : 한 건의 문서를 삭제한다.
- `Update API` : 한 건의 문서를 업데이트 한다 -> es는 업데이트라는 개념이 없으므로 삭제 후 추가로 실행 됩니다.

문서 관리 API는 한 건의 문서를 처리하는 기능이먀, `Single-document API` 라고도 부른다.
다수의 문서를 처리 할 경우는? `Multi-document API`도 제공한다!!
- `Multi Get API` : 다수의 문서를 조회한다.
- `Bulk API` : 대량의 문서를 색인한다.
- `Delete By Quer API`: 다수의 문서를 삭제한다.
- `Update By Query API` : 다수의 문서를 업데이트 한다.
- `Reindex API`: 인덱스의 문서를 다시 색인한다.

*일반적인 내용이므로 그냥 이런 API가 있다는 것만 알아 놓자.*

**문서 생성**
```json
POST /movie/_doc/1
{ 
    "movieCd" :"1",
    "movieNin" :"살아남은 아이", 
    "movieNmEn":"Last Child", 
    "prdtYear" :"2017", 
    "openDt" :"2017-10-20", 
    "typeNm" :"장편",
    "prdtStatNm" : "기 타",
    "nationAlt" : "한국" , 
    "genreAlt":"드라마,가족", 
    "repNationNm" : "한국", 
    "repGenreNm": "드라마"
}
```
- 결과는
```json
{
    "_index": "movie",
    "_type": "_doc",
    "_id": "1",
    "_version": 1,
    "result": "created",
    "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 0,
    "_primary_term": 1
}
```

**문서 조회**
```
GET /movie/_doc/1
```
- 결과는
```json
{
    "_index": "movie",
    "_type": "_doc",
    "_id": "1",
    "_version": 1,
    "found": true,
    "_source": {
        "movieCd": "1",
        "movieNin": "살아남은 아이",
        "movieNmEn": "Last Child",
        "prdtYear": "2017",
        "openDt": "2017-10-20",
        "typeNm": "장편",
        "prdtStatNm": "기타",
        "nationAlt": "한국",
        "genreAlt": "드라마,가족",
        "repNationNm": "한국",
        "repGenreNm": "드라마"
    }
}
```

**문서 삭제**
```
DELETE /movie/_doc/1
```
- 결과는
```json
{
    "_index": "movie",
    "_type": "_doc",
    "_id": "1",
    "_version": 2,
    "result": "deleted",
    "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 1,
    "_primary_term": 1
}
```

**id를 지정하지 않고 문서 생성**
```json
POST /movie/_doc
{ 
    "movieCd" :"1",
    "movieNin" :"살아남은 아이", 
    "movieNmEn":"Last Child", 
    "prdtYear" :"2017", 
    "openDt" :"2017-10-20", 
    "typeNm" :"장편",
    "prdtStatNm" : "기타",
    "nationAlt" : "한국" , 
    "genreAlt":"드라마,가족", 
    "repNationNm" : "한국", 
    "repGenreNm": "드라마"
}
```
- 결과는
```json
{
    "_index": "movie",
    "_type": "_doc",
    "_id": "LOpxnWsB2ZH0EWydX326",
    "_version": 1,
    "result": "created",
    "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
    },
    "_seq_no": 0,
    "_primary_term": 1
}
```
`id가 임의로 부여되었다!!`
    - es가 UUID를 통해 무작위로 생성한다.
        - UUID ? : 범용 고유 식별자 (https://ko.wikipedia.org/wiki/범용_고유_식별자)
    - database 기반 데이터를 색인할 경우 잘 쓰지 않을 듯.

### 2.2.3 검색 API
es 검색 API 사용방식은 다음과 같이 크게 두가지로 나뉜다.
- HTTP URI (Uniform Resource Identifier) 형태의 파라미터를 URI에 추가해 검색하는 방법
- RESTful API 방식인 QueryDSL을 사용해 요청 본문(Request Body)에 질의 내용을 추가해 검색하는 방법 : http://www.querydsl.com
```json
GET /movie/_doc/_search?q=prdtYear:2017&pretty=true
{
    "sort" :{ 
        "movieCd" : {
            "order" :"asc"
        }
    }
}
```
- 위 예제대로 하면 다음과 같은 에러가 납니다.
```json
{
    "error": {
        "root_cause": [
            {
                "type": "illegal_argument_exception",
                "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [movieCd] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead."
            }
        ],
        "type": "search_phase_execution_exception",
        "reason": "all shards failed",
        "phase": "query",
        "grouped": true,
        "failed_shards": [
            {
                "shard": 0,
                "index": "movie",
                "node": "Up2EY-UrSjGccqaNypZanw",
                "reason": {
                    "type": "illegal_argument_exception",
                    "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [movieCd] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead."
                }
            }
        ],
        "caused_by": {
            "type": "illegal_argument_exception",
            "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [movieCd] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead.",
            "caused_by": {
                "type": "illegal_argument_exception",
                "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [movieCd] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead."
            }
        }
    },
    "status": 400
}
```
- 요걸 참고 : https://rokking1.blog.me/221366675132
```json
PUT /movie/_mapping/_doc
{
    "properties" : {
        "movieCd" : {
            "type" : "text",
            "fielddata" : true
        }
    }
}
```
- 조회를 하면
```json
{
    "took": 4,
    "timed_out": false,
    "_shards": {
        "total": 3,
        "successful": 3,
        "skipped": 0,
        "failed": 0
    },
    "hits": {
        "total": 2,
        "max_score": null,
        "hits": [
            {
                "_index": "movie",
                "_type": "_doc",
                "_id": "1",
                "_score": null,
                "_source": {
                    "movieCd": "1",
                    "movieNin": "살아남은 아이",
                    "movieNmEn": "Last Child",
                    "prdtYear": "2017",
                    "openDt": "2017-10-20",
                    "typeNm": "장편",
                    "prdtStatNm": "기타",
                    "nationAlt": "한국",
                    "genreAlt": "드라마,가족",
                    "repNationNm": "한국",
                    "repGenreNm": "드라마"
                },
                "sort": [
                    "1"
                ]
            },
            {
                "_index": "movie",
                "_type": "_doc",
                "_id": "L-qhnWsB2ZH0EWydzX0X",
                "_score": null,
                "_source": {
                    "movieCd": "1",
                    "movieNin": "살아남은 아이",
                    "movieNmEn": "Last Child",
                    "prdtYear": "2017",
                    "openDt": "2017-10-20",
                    "typeNm": "장편",
                    "prdtStatNm": "기타",
                    "nationAlt": "한국",
                    "genreAlt": "드라마,가족",
                    "repNationNm": "한국",
                    "repGenreNm": "드라마"
                },
                "sort": [
                    "1"
                ]
            }
        ]
    }
}
```
    - `_shard`에서는 성공적으로 반환한 샤드의 수와 실패한 샤드의 수를 알 수 있다.
        - 검색에 실패한 샤드 수는 검색 시 설정된 `time_out`에 따라 결정된다.
        - `time_out` 시간이 초과되면 그때까지 검색된 내용까지만 결과로 반환된다.
        - 따라서 실패한 샤드의 수가 지나치게 많다면 `time_out` 시간을 조정해야 한다.
    - `hits` 에서는 일치하는 문서의 수와 함께 점수 (_score)가 가장 높은 상위 10개의 문서를 보여준다.

**URI 방식의 검색 질의**

다음과 같이 쿼리스트링만으로  ^^
```
GET /movie/_search?q=장편
```
- 파라미터를 사용할 때 별도의 필드명을 지정하지 않으면 존재하는 모든 필드를 대상으로 검색을 수행한다.
    - 특정 필드만 조회하고 싶다면 다음 코드와 같이 필드명을 포함해서 요청하면 된다.
        ```
        // typeNm 필드의 값이 '장편' 인 문자열 검색
        POST /movie/_search?q=typeNm:장편
        ```

**Request Body 방식의 검색 질의**

URI 검색 질의는 여러 필드를 각기 다른 검색어로 질의 하는 것이 어렵다.
- URI길이 제한 : "RFC 2068 - Hypertext Transfer Protocol -- HTTP/1.1" 에서 정의
    - https://www.rfc-editor.org/rfc/rfc2068.txt
    - >Note: Servers should be cautious about depending on URI lengths
    >above 255 bytes, because some older client or proxy implementations
    >may not properly support these lengths.

기본 구문은 다음과 같습니다.
```json
POST /{index명}/_search 
{
    JSON 쿼리 구문
}

// example
POST /movie/_search
{
    "query" : {
        "term" : {
            "typeNm" : "장편"
        }
    }
}
```
- 왜 POST여야 하는가!!
    - GET이어도 된다!! -> RESTful 하다면 GET이 맞지 않는가?

Request Body의 쿼리 구문은 다음과 같이 여러 개의 키 조합이 가능하다.

Key | 설명 | 기본값
----|----|----
size | `value` 몇 개의 결과를 반환할지 결정한다. | 10
from | `value` 어느 위치부터 반환할지를 결정한다.<br/>0부터 시작하면 상위 0~10건의 데이터를 반환한다. | 0
_source | `value` 특정 필드만 결과로 반환하고 싶을 때 사용한다.<br/>partial response | 
sort | `value` 특정 필드를 기준으로 정렬한다.<br/>asc, desc ... | 
query | `객체`. 검색될 조건을 정의한다. | 
filter | `객체`. 검색 결과 중 특정한 값을 다시 보여준다.<br/>결과 내에서 재검색할 때 사용하는 기능 중 하나다.<br/>다만 필터를 사용하게 되면 자동으로 score 값이 정렬되지 않는다. | 

### 2.2.4 집계 API
과거에는 통계 작업을 위해 루씬이 제공하는 `패싯(Facets)` 기능을 많이 활용했다.
- 11번가는 Solr 를 사용하여 Facets을 쓴다.
- Facets은 DB의 Group By와 동일한 개념이다.  
패싯은 기본적으로 디스크 기반으로 동작했고, 분산 환경에는 최적화 되지 않았기 때문에  
대용량 데이터의 통계 작업에는 적합하지 않았다.

ES는 5.0 이후 패싯 방식의 통계 기능을 제거하고 독자적인 집계 (Aggregation) API를 적용했다.  

>**루씬의 패싯 API**  
>패싯은 같은 항목의 총 개수를 푷시하는 기능으로,
>특정 필드를 기준으로 카테고리화해 총 개수를 취합 후 정렬한 결과를 제공한다.
>패싯 API는 시간 순으로 정렬할 수 없다.

**데이터 집계**
_serch API를 사용해 집계 쿼리를 만들고 terms 키워드를 이용해 genreAlt 필드의 데이터를 그룹화 해 보자.
```json
POST /movie/_search?size=0
{
    "aggs" : {
        "genre" : {
            "terms" : {
                "field" : "genreAlt"
            }
        }
    }
}
```
- 역시 에러가 발생할 것이다... genreAlt 필드에 `fielddata = true` 속성을 적용하자
```json
PUT /movie/_mapping/_doc
{
    "properties" : {
        "movieCd" : {
            "type" : "text",
            "fielddata" : true
        },
        "genreAlt" : {
        	"type" : "text",
        	"fielddata" : true
        }
    }
}
```

- 결과는 다음과 같다.
```json
{
    "took": 25,
    "timed_out": false,
    "_shards": {
        "total": 3,
        "successful": 3,
        "skipped": 0,
        "failed": 0
    },
    "hits": {
        "total": 2,
        "max_score": 0,
        "hits": []
    },
    "aggregations": {
        "genre": {
            "doc_count_error_upper_bound": 0,
            "sum_other_doc_count": 0,
            "buckets": [
                {
                    "key": "가족",
                    "doc_count": 2
                },
                {
                    "key": "드라마",
                    "doc_count": 2
                }
            ]
        }
    }
}
```

다음과 같이 버킷안에 다른 버킷의 결과를 추가 할수 있다.
```
POST /movie/_search?size=0
{
    "aggs": {
        "genre": {
            "terms": {
                "field": "genreAlt"
            },
            "aggs": {
                "nation": {
                    "terms": {
                        "field": "nationAlt"
                    }
                }
            }
        }
    }
}
```

**데이터 집계 타입**
집계 기능은 현재 4가지 API로 제공된다. 집계 기능은 서로 조합해서 사용할 수 있다.

집계 방법 | 설명
----|----
버킷 집계 (Bucket Aggregation) | 집계 중 가장 많이 사용한다.<br/>문서의 필드를 기준으로 버킷을 집계한다.
메트릭 집계 (Metric Aggregation) | 문서에 추출된 값을 가지고 Sum, Max, Min, Avg를 계산한다.
메트릭스 집계 (Metrix Aggregation) | 행렬의 값을 합하거나 곱한다.
파이프라인 집계 (Pipeline Aggregation) | 버킷에서 도출된 결과 문서를 다른 필드 값으로 재 분류한다.<br/>즉. 다른 집계에 의해 생성된 출력 결과를 다시 한번 집계한다.<br/>`집계가 패싯보다 강력한 이유가 여기에 있다.` 
<br/> 
<br/> 

# 3. 데이터 모델링
es는 색인할 때 문서의 데이터 유형에 따라 필드에 적절한 데이터 타입을 지정해야 한다.  
이러한 과정을 매핑이라고 하며, 매핑은 색인될 문서의 데이터 모델링이라고도 할 수 있다.  
사전에 매핑을 설정하면 지정된 데이터 타입으로 색인되지만 매핑을 설정해 두지 않으면 es가 자동으로 필드를 생성하고 필드 타입까지 결정한다.  
필드 데이터 타입이 자동으로 지정될 경우 실제 운영환경에서 예상하지 못한 오류가 발생할 수 있기 때문에 매핑 과정은 매우 중요한 과정이다.  
<br/> 

## 3.1 매핑 API 이해하기
매핑은 색인 시 데이터가 어디에, 어떻게 저장될지를 결정하는 설정이다.  
데이터베이스의 스키마에 대응하는 개념이라고도 할 수 있는데,  
인덱스에 추가되는 각 데이터 타입을 구체적으로 정의하는 일이다.  

다음과 같은 2개의 문서가 있다고 하고, 매핑 정의를 살펴 보자.  
```json
# 문서1
{
    "movieCd" : "20173732",
    "movieNm":"캡틴 아메리카"
}
# 문서2 
{
    "movieCd" : "XTQQI",
    "movieNm" :"아이언맨"
}
```
- 문서1 색인시 매핑설정이 없어 movieCd는 `숫자` 타입이 된다.
- 문서2 색인시 movieCd가 `문자` 라 오류가 발생한다.
- 즉, 여러 타입이 혼재된 필드의 경우 색인 오류가 발생 될 수 있다.  

매핑 정보를 설정 할 경우 다음 사항을 고민해야 한다.
> - 문자열을 분석할 것인가?
> - _source에 어떤 필드를 정의할 것인가?
> - 날짜 필드를 가지는 필드는 무엇인가?
> - 매핑에 정의되지 않고 유입되는 필드는 어떻게 처리할 것인가?
<br/>

### 3.1.1 매핑 인덱스 만들기
영화 정보를 다음과같은 매핑 설정으로 만들어 보자
매핑명 | 필드명 | 필드 타입
---|---|---
인덱스 키 | movieCd | keyword
영화제목_국문 | movieNm | text
영화제목_영문 | movieNmEn | text
제작연도 | prdtYear | integer
개봉연도 | openDt | integer
영화유형 | typeNm | keyword
제작상태 | prdtStatNm | keyword
제작국가(전체) | nationAlt | keyword
장르(전체) | genreAlt | keyword
대표 제작국가 | repNationNm | keyword
대표 장르 | repGenreNm | keyword
영화 감독명 | directors.peopleNm | object -> keyword
제작사 코드 | companies.companyCd | object -> keyword
제작사 명 | companies.companyNm | object -> keyword

색인 데이터는 다음과 같다.
```json
{
    "movieCd": "20173732", 
    "movieNm": "살아남은 아이", 
    "movieNmEn":"Last Child", 
    "prdtYear": "2017", 
    "openDt" : "",
    "typeNm":"장편", 
    "prdtStatNm": "기타", 
    "nationAlt" :"한국", 
    "genreAlt":"드라마,가족", 
    "repNationNm": "한국", 
    "repGenreNm":"드라마", 
    "directors" :[{
        "peopleNm": "신동석"
    }],
    "companies" :[{
        "companyCd": "", 
        "companyNm": ""
    }]
}
```
- `text` 타입은 검색 가능한 속성이다.
- `keyword` 타입은 검색 불가능한 속성이다.

매핑 설정은 다음과 같다.
```json
PUT movie_search 
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1
  },
  "mappings": {
    "_doc": {
      "properties": {
        "movieCd": {
          "type": "keyword"
        },
        "movieNm": {
          "type": "text",
          "analyzer": "standard"
        },
        "moviNmEn": {
          "type": "text",
          "analyzer": "standard"
        },
        "prdtYear": {
          "type": "integer"
        },
        "openDt": {
          "type": "integer"
        },
        "typeNm": {
          "type": "keyword"
        },
        "prdtStatNm": {
          "type": "keyword"
        },
        "nationAlt": {
          "type": "keyword"
        },
        "genreAlt": {
          "type": "keyword"
        },
        "repNationNm": {
          "type": "keyword"
        },
        "repGenreNm": {
          "type": "keyword"
        },
        "companies": {
          "properties": {
            "companyCd": {
              "type": "keyword"
            },
            "companyNm": {
              "type": "keyword"
            }
          }
        },
        "directors": {
          "properties": {
            "peopleNm": {
              "type": "keyword"
            }
          }
        }
      }
    }
  }
}
```

결과는
```json
{
    "acknowledged": true,
    "shards_acknowledged": true,
    "index": "movie_search"
}
```

### 3.1.2 매핑 확인
```
GET movie_search/_mapping
```

### 3.1.3 매핑 파라미터
매핑 파라미터는 색인할 필드의 데이터를 어떻게 저장할지에 대한 다양한 옵션을 제공한다. 

__analyzer__  
> 형태소 분석을 하기 위해 설정한다. <br/>색인과 검색시 지정한 분석기로 형태소 분석을 수행한다.<br/>`text` 타입은 `analyzer` 매핑 파라미터를 기본으로 사용해야 한다.<br/>기본값은 Standard Analyzer 이다.<br/>

__normalizer__  
> term query에 분석기를 사용하기 위해 설정한다.<br/> 예를 들어 `keyword` 타입의 경우 원문을 기준으로 문서가 색인되기 때문에 cafe, Cafe 는 서로 다른 문서로 인식된다.<br/> normalizer > asciifolding과 같은 필터를 사용하면 같은 데이터로 인식되게 할 수 있다.  <br/>

__boost__  
> 필드에 가중치(`weight`)를 부여한다. <br/>가중치에 따라 유사도 점수(`_scope`)가 달라지기 때문에 boost 설정 시 검색 결과의 노출 순서에 영향을 준다.<br/>만약 색인 시점에 boost 설정을 하게되면 재색인시에만 반영이 된다.<br/>`가급적 검색 시점에만 사용하는 것을 권장한다.`<br/>최신 es는 색인 시 boost 설정을 할 수 없도록 바뀌었다. 루씬 7.0 부터 제거 되었기 때문에....  <br/>

__coerce__  
> 색인 시 자동 변환을 허용할지 여부를 설정하는 파라미터다.<br/>예를 들어 "10"과 같은 숫자 형태의 문자열이 integer 타입의 필드에 들어온다면, es는 자동으로 형변환을 하여 정상처리하려 한다.<br/>하지만 coerce 설정을 미사용으로 변경한다면 색인에 실패할 것이다.  <br/>

__copy_to__  
> 매핑 파라미터를 추가한 필드의 값을 지정한 필드로 복사한다.<br/>keyword 타입의 필드에 `copy_to` 로 다른 필드로 복사하고, 복사된 필드에 text 타입을 지정헤 형태소 분석을 할 수도 있다.<br/>또한 여러개의 필드 데이터를 하나의 필드에 모아서 전체 검색 용도로 사용하기도 한다.<br/>과거에 존재하던 _all 컬럼과 동일한 기능을 제공할 수 있다.  <br/>

__fielddata__  
> es가 힙 공간에 생성하는 메모리 캐시다.<br/>과거에는 `fielddata`를 많이 사용했지만 반복적인 메모리 부족 현상과 잦은 GC로 현재는 거의 사용되지 않는다.<br/>최신 버전의 es는 `doc_values`라는 새로운 캐시를 제공하고 있으며, text타입의 필드를 제외한 모든 필드는 기본적으로 doc_values 캐시를 사용한다.<br/><br/>fielddata를 사용해야만 하는 경우도 있다.<br/>`text타입의 필드는 기본적으로 분석기에 의해 형태소 분석이 되기 때문에 집계나 정렬등의 기능을 수행할 수 없다.` <br/> 하지만 부득이 하게 text타입의 필드에서 집계나 정렬을 수행할 경우 fielddata를 사용해야 한다.<br/> fielddata는 메모리에 생성되는 캐시이기 때문에 최소한으로만 사용해야 한다.<br/>기본값은 비활성화 이다. -> 메모리 소모가 크기 때문에.  <br/>

__doc_values__  
> es에서 사용하는 기본 캐시다.<br/>text타입을 제외한 모든 타입에서 기본적으로 `doc_values` 캐시를 사용한다.<br/>doc_values는 루씬을 기반으로 하는 캐시 방식이다.<br/>

__dynamic__
> 매핑에 필드를 추가할 때 동적으로 생성할지, 생성하지 않을지를 결정한다.  
> 동적 생성 필드의 처리 방법으로 다음 세가지중 하나를 지정할 수 있다.

인자 | 설명
--- | ---
true | 새로 추가되는 필드를 매핑에 추가한다.
false | 새로 추가되는 필드를 무시한다.<br/>해당 필드는 색인되지 않아 검색할 수 없지만 _source에는 표시된다.
strict | 새로운 필드가 감지되면 예외가 발생하고 문서 자체가 색인되지 않는다.<br/>새로 유입되는 필드는 사용자가 매핑에 명시적으로 추가해야 한다. 

